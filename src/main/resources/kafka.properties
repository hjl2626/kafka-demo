# 生产者配置
kafka.producer.brokers=192.168.109.130:9092
# 分区数
kafka.producer.partitionNumber=3

# 生产者数
kafka.producer.producerNum=3
# 0 ,1 ,all
kafka.producer.required_acks=1
# topic
kafka.producer.topicName=ubuntu-test3
# message
kafka.producer.message=producer


kafka.producer.bufferMemory=3355

kafka.producer.retries=0

kafka.producer.batchSize=50

# 等多久，如果buffer没满，比如设为1，即消息发送会多1ms的延迟，如果buffer没满
linger.ms = 1000



kafka.producer.keySerializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.valueSerializer=org.apache.kafka.common.serialization.StringSerializer




# 消费者配置
kafka.consumer.consumerNumber=6
kafka.consumer.zookeeper_connects=192.168.109.130:2181
kafka.consumer.zookeeper_timeout=10000
kafka.consumer.topicName=ubuntu-test
kafka.consumer.groupName=group


# socket用于接收网络请求的缓存大小 默认值64*1024
#kafka.consumer.socket.receive.buffer.bytes=64*1024

# 每次fetch请求中，针对每次fetch消息的最大字节数。这些字节将会督导用于每个partition的内存中，
#因此，此设置将会控制 consumer所使用的memory大小。这个fetch请求尺寸必须至少和server允许的最大消息尺寸相等，
#否则，producer可能发送的消 息尺寸大于consumer所能消耗的尺寸。默认1024*1024
# kafka.consumer.fetch.message.max.bytes = 1024*1024

# 用于fetch数据的fetcher线程数 默认为1
# num.consumer.fetchers=1

# 如果为真，consumer所fetch的消息的offset将会自动的同步到zookeeper。这项提交的offset将在进程挂掉时，由新的consumer使用
# auto.commit.enable=true

# consumer向zookeeper提交offset的频率，单位是ms
kafka.consumer.auto.commit.interval.ms =60000

# zookeeper中没有初始化的offset时，如果offset是以下值的回应：
# * smallest：自动复位offset为smallest的offset
# * largest：自动复位offset为largest的offset
# * anything ?else：向consumer抛出异常）
kafka.consumer.auto.offset.reset=smallest

# 如果没有消息可用，即使等待特定的时间之后也没有，则抛出超时异常
# consumer.timeout.ms=-1